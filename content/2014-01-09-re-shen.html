<html>
    <head>
        <title>开始算法逼近误差分析之前的一点儿热身活动</title>
        <meta name="tags" content="Machine learning, Loss function" />
        <meta name="date" content="2014-01-09 10:28" />
        <meta name="modified" content="2014-01-09 10:28" />
        <meta name="category" content="Loss function" />
        <meta name="authors" content="LCY.Seso" />
        <meta name="summary" content="Short version for index and feeds" />
		<meta name="image" content="images/140109-feature.png">
		
		<script type="text/javascript"
			src="https://d3eoax9i5htok0.cloudfront.net/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>
    </head>
    <body>
		<script type="text/javascript"
		  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>
		
<div style="line-height:200%">
	<div>
		<div>
			<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span">博客里写的小文章涉及到的任何知识一定指明原始资料，保证绝无一遗漏。如果对我的理解存有疑问请尽情翻阅原始资料。</span></span></span>
		</div>

		<div style="text-align: center; ">
			<strong><span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><span data-wiz-span="data-wiz-span">1. 逼近误差和近似误差</span></span></span></span></strong>
		</div>

		<p>
			<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><!--more--> </span></span></span>
		</p>

		<div>
			<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;">目前我们暂时只考虑二分类问题，使用\(\{-1, ~+1\}\)表示两类的类别标签。</span></span>
		</div>

		<div>
			&nbsp;
		</div>

		<div>
			<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><span data-wiz-span="data-wiz-span">学习算法可以看作是搜索算法：从假设空间\(\mathcal{H}\)中搜索令损失函数的期望风险最小的假设。算法选择出的\(\tilde{f} (\boldsymbol{x})\)是在经验风险最小化准则下对最优决策\(f^*(\boldsymbol{x})\)的逼近。算法选择的假设空间\(\mathcal{H}\)在学习过程中起着重要作用。假设空间过于复杂，搜索最优解的时间长，同时也增大了过拟合的风险；假设空间过于简单，可能会导致拟合训练数据的能力不足。选择合适的假设空间也是学习算法中非常重要的部分。各种常用的学习算法基本上都有自己默认的假设空间，在具体化一个算法时，通常通过选择不同的规则化项，或者调节规则化参数来限定模型复杂度。我们总是希望算法选择的假设空间中恰好包含真实假设\(f^*(\boldsymbol{x})\)，但是也不可强求，毕竟真实模型到底是什么，谁也不知道。</span></span></span></span>
		</div>

		<div>
			&nbsp;
		</div>

		<div>
			<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><span data-wiz-span="data-wiz-span">既然\(\tilde{f}(\boldsymbol{x})\)只是\(f^*(\boldsymbol{x})\)的近似，那么我们非常关心使用\(\tilde{f}(\boldsymbol{x})\)分类的期望错误率和使用\(f^*(\boldsymbol{x})\)分类的期望错误率相差了多少，这对评价\( \tilde{f}(\boldsymbol{x}) \)是否是\(f^*(\boldsymbol{x})\)的一个良好的近似，对比较不同算法都有重要作用。</span></span></span></span><span style="font-family: 'times new roman', times, serif; font-size: 15.833333015441895px; line-height: 26.66666603088379px; ">（<span style="font-size:14px;"><span style="color:#008000;">这里需要一些咬文嚼字，期望错误率是取0-1损失为损失函数计算出的期望风险，与基于其他代理损失函数计算出的期望风险是有差别的，期望错误率最小化是分类问题的终极目标。在没有进行严谨地验证之前，不能简单认为令基于代理损失函数的期望风险最小的决策一定也能让期望错误率最小。尽管仔细地选择损失函数，他们的确是等价的，但在没有经过严密验证之前，这个结论依然是值得怀疑的。其实，新的发现可能都是从揪住细节穷追猛打得到的。<img alt="smiley" height="20" src="http://www.lovecaoying.com/blog/wp-content/plugins/ckeditor-for-wordpress/ckeditor/plugins/smiley/images/regular_smile.gif" title="smiley" width="20" /></span></span></span><span style="font-family: 'times new roman', times, serif; font-size: 15.833333015441895px; line-height: 26.66666603088379px; ">）</span>
		</div>

		<div>
			&nbsp;
		</div>

		<div>
			<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><span data-wiz-span="data-wiz-span">首先需要分析哪些因素导致\(\tilde{f}(\boldsymbol{x})\)与最优决策\(f^*(\boldsymbol{x})\)的期望错误率之间存在差别？不难明白这个</span><span data-wiz-span="data-wiz-span">误差包括两部分。</span></span></span></span>
		</div>

		<div>
			&nbsp;
		</div>

		<div style="text-align: center; ">
			<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><span data-wiz-span="data-wiz-span">（1）. 逼近误差 （Approximation Error）</span></span></span></span>
		</div>

		<div>
			&nbsp;
		</div>

		<div>
			<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><span data-wiz-span="data-wiz-span">记\(\bar{f} = \underset{f \in \mathcal{H}} \min E_{XY}[~\mathcal{L}(yf( \boldsymbol{x})~]\)是假设空间\(\mathcal{H}\)中令损失函数期望风险最小的决策（可能不唯一）。如果算法运行结束能够找到\(\bar{f}(\boldsymbol{x})\)，可以认为算法输出假设的期望错误率与最优决策的望错误率之差为0。但是谁也不知道最优决策到底是什么，所以最好还是不要有如此乐观的期待，更令人安心的分析应该告诉我们最坏情况会有多糟糕。所以，应该考虑到假设空间\(\mathcal{H}\)中并不包含真实假设的情况。这时\(\bar {f}(\boldsymbol{x})\)分类的期望错误率与\( f^*(\boldsymbol{x}) \)分类的期望错误率之差不为0，这部分和算法选择什么样的训练样本，选择多少训练样本无关，只和假设空间有关的误差是逼近误差。</span></span></span></span>
		</div>

		<div>
			&nbsp;
		</div>

		<div style="text-align: center; ">
			<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><span data-wiz-span="data-wiz-span">（2）. 估计误差 （Estimation Error）</span></span></span></span>
		</div>

		<div>
			&nbsp;
		</div>

		<div>
			<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><span data-wiz-span="data-wiz-span">\(\tilde{f}(\boldsymbol{x})\)的另一部分误差和训练样本以及优化算法有关。</span></span></span></span>
		</div>

		<div>
			&nbsp;
		</div>

		<div>
			<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><span data-wiz-span="data-wiz-span">对于&ldquo;使用多少个样本进行训练&rdquo;这个问题，通常的建议都会是：越多越好。如果能够取遍样本空间中的所有样本（也意味着能够对样本空间中的样本分布进行准确估计），至少可以做一个查找表，效率不一定高，但保证一定能够正确分类所有样本。这种做法是不可能也是不可取的。先不考虑效率问题，获取样本是有代价的，永远只能拿到样本空间中的一个采样样本集，通常还总是需要假定采样是足够好的，或者假设存在某种可以分析的缺陷（比如单类分类任务，只假设一类样本采样充分，不对另一类样本进行任何假设），然后通过这个采样样本集，对整个样本空间中样本呈现出的分布特征进行估计。算法输出决策\(\tilde{f}(\boldsymbol{x})\)对未知样本分类就（显式或隐式地）建立在对整个样本空间中样本分布的估计之上。选择多少个训练样本，训练样本集采样是否充分，训练样本集是否在样本分布的每个概率密度区域都有足够的采样，最终都会影响到对整个样本空间中样本分布情况的估计。</span></span></span></span>
		</div>

		<div>
			&nbsp;
		</div>

		<div>
			<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><span data-wiz-span="data-wiz-span">与此同时，学习过程中最核心的搜索算也会引起误差。尽管理想情况不可得，但是对任意给定的训练样本集\(S\)，如果搜索算法总是能找到假设空间\(\mathcal{H}\)中对训练样本最佳拟合的决策，也就意味着在理想情况下，算法一定也能够找到假设空间中对样本分类期望错误率最小的决策\(\bar{f}(\boldsymbol{x})\)&nbsp;。相反，如果寻找全局最优解过于复杂，就会转而寻找可以接受的次优解。这时候，即使在理想情况下算法输出决策与假设空间中的最优决策之间也存在误差，更不用说，假设空间可能并不包含最优决策。</span></span></span></span><span style="font-family: 'times new roman', times, serif; font-size: 16px; line-height: 200%; ">这部分与训练样本和优化算法有关的误差就是估计误差。</span>
		</div>

		<div>
			&nbsp;
		</div>

		<div>
			<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><span data-wiz-span="data-wiz-span">这两种误差中，估计误差是无法避免的，但是一个理论上经得起检验的学习算法应该保证在极限情况下，收敛到假设空间中的最优决策，这是学习算法分析最关心的部分。</span></span></span></span>
		</div>

		<div>
			&nbsp;
		</div>

		<div>
			<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><span data-wiz-span="data-wiz-span">如果对遵循&ldquo;对代理损失函数（</span></span></span></span><span style="font-family: 'times new roman', times, serif; font-size: 15.833333015441895px; line-height: 26.66666603088379px; ">0-1损失函数的一个凸上界</span><span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><span data-wiz-span="data-wiz-span">）进行凸优化&rdquo;的学习算法进行理论分析，会看到选择不同的损失函数得到的逼近误差并不相同。这其中还有一个环节，验证令代理损失函数下的期望风险最小也会令0-1损失下的期望错误率最小，分析可以参考张潼老师的论文[1]，以及另一篇更早的研究论文[2]，当然我也想试着自己去分析。</span></span></span></span>
		</div>

		<div>
			&nbsp;
		</div>

		<div>
			<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><span data-wiz-span="data-wiz-span">这些论文的结论是：SVM使用的Hinge Loss会得到最小逼近误差。但是其它损失函数也不差，这点逼近误差上的差别，在实际应用中基本感受不到。同时，损失函数也会影响收敛速率。</span></span></span></span>
		</div>

		<div>
			&nbsp;
		</div>

		<div>
			<font face="times new roman, times, serif"><span style="font-size: 15.833333015441895px;">在开始对算法逼近误差，以及泛化误差界分析之前，还需要一些准备活动，活动活动大脑，找到一些算法分析的感觉。</span></font>
		</div>

		<div>
			&nbsp;
		</div>

		<div>
			<hr />
		</div>

		<div>
			&nbsp;
		</div>

		<div style="text-align: center; ">
			<strong><span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><span data-wiz-span="data-wiz-span">2. 学习问题的一个简单概率解释</span></span></span></span></strong>
		</div>

		<div style="text-align: center; ">
			&nbsp;
		</div>

		<p>
			&nbsp;
		</p>
	</div>

	<div>
		<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><span data-wiz-span="data-wiz-span">假定输出空间\(Y=\{ \pm 1\}\)，输入空间\(X\)，\(P\)是\(X \times Y\)之上的联合概率分布。\(P(XY) = P(X)P(Y|X) \)，因此可以用二元组\((\mu, \eta)\)表示\(X \times Y\)上的联合概率\(P(XY)\)，\( \eta (\boldsymbol{x}) =\mathbb{E} [Y|X] =P(Y=1|X=1)\)，\(\mu(\boldsymbol{x})\)是联合分布\(P(XY)\)关于\(X\)的边缘分布。</span></span></span></span>
	</div>

	<div>
		&nbsp;
	</div>

	<div>
		<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><span data-wiz-span="data-wiz-span">\(\mathcal{L}(y,f(\boldsymbol{x})): Y \times Y \to R\)是损失函数，决策\(f(\boldsymbol{x})\)的期望风险\(R(f)\)是损失函数\(\mathcal{L}(y, f(\boldsymbol{x}))\)在联合概率分布\(P(XY)\)下期望：\(R(f) = \mathbb{E}_{XY} [\mathcal{L }(y,f(\boldsymbol{x})]\)，学习算法的目标是令期望错误率最小。</span></span></span></span>
	</div>

	<div>
		&nbsp;
	</div>

	<div>
		<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><span data-wiz-span="data-wiz-span">前面已经提到过，0-1损失函数不便于数值优化，学习算法通常都需要转而使用代理损失函数。这些代理损失函数是0-1损失的凸上界（凸性条件可以放宽，但不在目前的研究范围内）。</span></span></span></span><span style="font-family: 'times new roman', times, serif; font-size: 15.833333015441895px; line-height: 26.66666603088379px; ">毕竟0-1损失的凸上界并不是0-1损失函数本身，</span><span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><span data-wiz-span="data-wiz-span">在这个过程中，还需要验证优化0-1损失的凸上界同样会令期望错误率最小（这次我们还做不到）。</span></span></span></span>
	</div>

	<div>
		&nbsp;
	</div>

	<div>
		<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span">0-1损失函数：\(\mathcal{L}_{0-1}= \left\{\begin{align}&amp;1,&amp; y \ne f(\boldsymbol{x}) &nbsp;\\ &amp;0, &amp; y=f(\boldsymbol{x})\end{align}\right.\)是分类问题天生的损失函数，我们需要知道令0-1损失最小的决策是什么，然后才能够计算其他非最优决策与最优决策的差。</span><span data-wiz-span="data-wiz-span">为了与后面会出现的基于代理损失函数的期望风险有所区别，将基于0-1损失函数的期望风险直接称作期望错误率。令期望错误率最小是分类问题的最终目标。取\(\mathcal{L}\)为0-1损失。</span></span></span>
	</div>

	<div>
		<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span">\[ \begin{align} R(f)=&amp; \mathbb{E}_{XY} [\mathcal{L}(f(\boldsymbol{x}),y)]\\ =&amp; \mathbb{E}_X\mathbb{E}[\mathcal{L}(f(\boldsymbol{x}),y)|\boldsymbol{x}] \\ =&amp; \mathbb{E}_X \left[ \mathbb{E} \left[ &nbsp;\mathcal{L}(f(\boldsymbol{x}),1)P(Y=1|\boldsymbol{x})+\mathcal{L}(f(\boldsymbol{x}),-1)P(Y=-1)\right]\right]\\=&amp;\mathbb{E}_X[I[f(\boldsymbol{x})\ne 1]\eta(\boldsymbol{x})+I[f(\boldsymbol{x})\ne-1](1-\eta(\boldsymbol{x}))] \\=&amp; \mathbb{E}_X[I[f(\boldsymbol{x})\ne1]\eta(\boldsymbol{x})+(1-I[f(\boldsymbol{x}) \ne 1])(1-\eta(\boldsymbol{x}))] \\=&amp;\mathbb{E}_X[I[f(\boldsymbol{x}) \ne 1](2\eta(\boldsymbol{x})-1)+1-\eta(\boldsymbol{x})] \label{1}\tag{1}\end{align}\]为了令\(\eqref{1}\)式最小，当\(2 \eta(\boldsymbol{x}) -1 \geq 0\)时，\( I[f(\boldsymbol{x}) \ne 1] \) 应该等于0；当\(2\eta(\boldsymbol{x}) -1 <0 \)时，\(I[f(\boldsymbol{x}) \ne 1]\)应该等于1。满足这一条件的\(f^*(\boldsymbol{x})\)正是熟悉的贝叶斯决策：\[f^*(\boldsymbol{x})= \left\{ \begin{align} &amp;1 &nbsp;&amp; \eta(\boldsymbol{x} )\geq 0.5 \\ &amp; -1 &amp; \eta(\boldsymbol{x})<0.5\end{align} \right. \tag{2} \label{2}\]</span></span></span>
	</div>

	<div>
		<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span">学习算法通常找到最优决策\(f^*(\boldsymbol{x})\)的一个估计\(f(\boldsymbol{x})\)，我们希望\(f(\boldsymbol{x})\)的期望错误率与最优决策\(f^*(\boldsymbol{x})\)的期望错误率相比，不会相差太多。接下来考察</span><span data-wiz-span="data-wiz-span">对任意\(f(\boldsymbol{x}) : X \to Y\)，\(f(\boldsymbol{x}) \ne f^*(\boldsymbol{x})\)，\(R(f) -R(f^*)\)相差了多少。</span><span data-wiz-span="data-wiz-span">由\(\eqref{1}\)式的结论可得：\[\begin{align} R(f)-R(f^*) =&amp; \mathbb{E}_X \bigg [ I[f(\boldsymbol{x})\ne 1]-I[f^*(\boldsymbol{x})\ne 1]\bigg ](2\eta(\boldsymbol{x})-1) \\ =&amp; \mathbb{E}_X \bigg [ I[f(\boldsymbol{x})\ne f^*(X)](I [f(\boldsymbol{x})\ne 1]-I[f^*(\boldsymbol{x})\ne 1])(2\eta(\boldsymbol{x})-1) \bigg ]\\=&amp; \left \{ \begin{array}{} \mathbb{E}_X \bigg [I[f(\boldsymbol{x})\ne f^*(\boldsymbol{x})] \bigg](2\eta(\boldsymbol{x})-1) &amp;\quad\text{if}\quad \eta(\boldsymbol{x}) \geq0.5 \\ \mathbb{E}_X \bigg [ I[f(\boldsymbol{x}) \ne f^*(\boldsymbol{x})]\bigg ](-1)(2\eta(\boldsymbol{x})-1)&amp;\quad \text{if} \quad\eta(\boldsymbol{x})<0.5\end{array}\right. \tag{3} \label{3}\\ =&amp; \mathbb{ E}_X \bigg [I[f(\boldsymbol{x})\ne f^*(\boldsymbol{x})] \left | 2\eta(\boldsymbol{x})-1 \right | \bigg ] \tag{4} \label{4} \end{align}\]从\(\eqref{3}\)式到\(\eqref{4}\)式是根据\(f^*(\boldsymbol{x})\)的定义\(\eqref{2}\)。\(\eqref{4}\)式实际上指示了一种解决分类问题的方法。为了保证算法出输出决策\(f(\boldsymbol{x})\)的期望错误率与最优决策\(f^*(\boldsymbol{x})\)的期望错误率相差尽可能小，应该令样本空间中\(f(\boldsymbol{x}) \ne f^*(\boldsymbol{x})\)成立的区域尽可能小（看上去这是常识，显而易见。。。），考虑\(f^*(\boldsymbol{x})\)的定义，可以</span><span data-wiz-span="data-wiz-span">通过给定的训练数据建立起\(\eta(\boldsymbol{x})\)的估计\(\tilde{\eta} (\boldsymbol{x})\)，然后构造决策函数\( f_{\tilde{\eta}} (\boldsymbol{x})= \left \{ \begin{align} &amp; 1 &amp;\tilde{\eta}(\boldsymbol{x}) \geq 0.5 \\&amp; -1 &amp; \tilde{\eta}(\boldsymbol{x}) &lt;0.5 \end{align}\right.\)。</span></span></span>
	</div>

	<div>
		&nbsp;
	</div>

	<div>
		<span style="font-size:16px;"><span data-wiz-span="data-wiz-span"><font face="times new roman, times, serif">这种方法看上去是不是有一点&ldquo;废话&rdquo;，不就是判别法中的直接估计后验概率嘛。</font>如果上面的结论只是告诉我们：估计后验概率，然后选择后验概率大一类对应的类别标签作为输出，贝叶斯决策不是早就这么说了，为什么还要重复这个结论？首先，贝叶斯决策可没有说当后验概率估计与真实后验概率有差距的时候，决策的期望错误率会差多少，上面的的结论计算了这个差值，尽管这个计算很简单。另一方面，</span><span style="font-family: 'times new roman', times, serif; line-height: 200%; ">这是不仅</span><span style="font-family: 'times new roman', times, serif; line-height: 200%; ">一种看上去有些理想化的建立学习算法的方法，也可以看作是从不同的角度理解决策\(f(\boldsymbol{x})\)，建立决策函数 \(f(\boldsymbol{x})\)与后验概率之间的联系。复杂的结果往往都是以显而易见的命题为基础构建起来的。再想一想，</span></span><span style="font-family: 'times new roman', times, serif; font-size: 16px; line-height: 200%; ">决策函数\(f(x)\)可以不仅仅是后验概率估计\(\tilde{\eta}(\boldsymbol{x}) \ge 0.5\)时输出1，反之输出-1这样简单的形式，也可以是以\(\tilde{\eta}(\boldsymbol{x})\)为变量的任何形式的函数，只要这个函数对\(\tilde{\eta}(\boldsymbol{x})\)单调，当\(\tilde{\eta}(\boldsymbol{x}) =0.5\)时，\( f ( \tilde{ \eta} ( \boldsymbol{x}))=0 \)。后面会继续用加强这种观点。</span>
	</div>

	<div>
		&nbsp;
	</div>

	<div>
		<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span">​学习的过程通常都是解优化问题的过程，除非一步就能得到最优解，否则解优化问题需要一个&ldquo;准则&rdquo;，告诉我们什么样的解质量好，什么样的解质量差，那么，继续上面的分析很自然会问，在估计\(\eta(\boldsymbol{x})\)时，应该选择什么样的准则？为了回答这个问题，我们需要考察任意\(f_{\tilde{\eta}}\)的期望错误率与贝叶斯决策的期望错误率相差多少。由\(\eqref{4}\)式得：</span><span data-wiz-span="data-wiz-span">\[ R(f_{\tilde{\eta}}) -R^* = 2\mathbb{E}_X\left[ ~I[f_{\tilde{\eta}}(\boldsymbol{x}) \ne f(\boldsymbol{x})]~\right] \left| \eta(\boldsymbol{x})-\frac{1}{2} \right| \tag{5}\label{5}\]略微思考一下会发现，对任意使不等式\(f_{\tilde{\eta}}(\boldsymbol{x}) \ne f(\boldsymbol{x})\)成立的\(\boldsymbol{x}\)，都有\(\tilde{\eta}(\boldsymbol{x})\)和\( \eta (\boldsymbol{x})\)在0.5 的两侧，因此可得：\[\begin{equation} \begin{split} \left|\eta(\boldsymbol{x})-\tilde{\eta}(\boldsymbol{x}) \right| =&amp;\left|\eta(\boldsymbol{x})-\frac{1}{2} \right|+\left|\tilde{\eta}(\boldsymbol{x})-\frac{1}{2}\right| \\ \geq&amp; \left | \eta(\boldsymbol{x})-\frac{1}{2} \right| \end{split} \end{equation} \tag{6} \label{6} \]当\(\eqref{5}\)式中的指标函数\(I \left[f_{\tilde{\eta}} (\boldsymbol{x}) \ne f(\boldsymbol{x}) \right]\)取值为1时，也就是命题\(f_{\tilde{\eta}}(\boldsymbol{x}) \ne f(\boldsymbol{x})\)成立的情况下，将\(\eqref{6}\)带入\(\eqref{5}\)，得到：\[R(f_{\tilde{\eta}})- R^* \le 2 \mathbb{E}_X\bigg[\left| \eta(\boldsymbol{x})-\tilde{\eta}(\boldsymbol{x}) \right| \bigg] \tag{7} \label{7}\]这个结论指出可以使用：&ldquo; 距离最优决策 \(\eta^*(\boldsymbol{x})\)的\(L_1(\mu)\)距离最小 &rdquo; 作为优化准则</span></span></span><span style="font-family: 'times new roman', times, serif; font-size: 15.833333015441895px; line-height: 26.66666603088379px; ">（上面定义了\(\mu\)是联合分布\(P(XY)\)关于\(X\)的边缘分布）</span><span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span">。</span></span></span>
	</div>

	<div>
		&nbsp;
	</div>

	<div>
		<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span">好了，我们又会发现，这几乎又是一个&ldquo;废话&rdquo;结论，因为真实后验概率是无法知道的，也就无法度量与最优决策之间的距离，这个优化准则是没有意义的。</span></span></span><span data-wiz-span="data-wiz-span" style="font-size: 16px; font-family: 'times new roman', times, serif; line-height: 200%; ">用同样废话的我自己对理论分析的小小感受作为在这一篇里对这个问题的回答，以及这一篇的结束。</span><span style="font-family: 'times new roman', times, serif; font-size: 16px; line-height: 200%; ">在下一篇开始，我想试着对一些算法的逼近误差进行分析，将之前写过的Bregman散度，以及对损失函数的解释全部联系起来，然后会看到这些看上去&ldquo;废话&rdquo;的结果，最终会发挥作用，是更深刻结论的基础。</span>
	</div>

	<div>
		&nbsp;
	</div>

	<div>
		<span data-wiz-span="data-wiz-span" style="font-size: 16px; font-family: 'times new roman', times, serif; line-height: 200%; ">在翻阅资料的时候，我会觉得围绕着损失函数的问题很难很快理解，很难很快就做出一个看得到效果的算法，但是我相信学习理解他，思考实践，最终才可以帮助我做出效果更好的算法，因为优化是学习过程的核心，而优化目标又是优化问题的根本。我想试着不以抛出不明觉厉的结论为目的，</span><span style="font-family: 'times new roman', times, serif; font-size: 15.833333015441895px; line-height: 31.66666603088379px; ">而是对过去学习过的分散的资料进行整体的理解，将分散的结论联系起来。其实，</span><span data-wiz-span="data-wiz-span" style="font-size: 16px; font-family: 'times new roman', times, serif; line-height: 200%; ">这些结论都是前辈做出来的，在很长一段时间内，我都是从做学习者开始的。</span>
	</div>

	<div>
		&nbsp;
	</div>

	<div>
		<span data-wiz-span="data-wiz-span" style="font-size: 16px; font-family: 'times new roman', times, serif; line-height: 200%; ">By the way，这一篇的第2节写到的推导是对</span><span style="font-size: 16px; font-family: 'times new roman', times, serif; line-height: 200%; ">Berkeley CS 281B，Statistical Learning Theory 这门课程Lecture 1的Lecture Note的重复展示和我自己的理解</span><span style="font-family: 'times new roman', times, serif; font-size: 15.833333015441895px; line-height: 31.66666603088379px; ">，</span><span style="font-family: 'times new roman', times, serif; font-size: 15.833333015441895px; line-height: 31.66666603088379px; ">私以为有了这点分析，对接下来要做的算法的逼近误差分析有些帮助。</span><span style="font-size: 16px; font-family: 'times new roman', times, serif; line-height: 200%; ">我也是在看论文的过程中偶然发现这个课程，觉得课程的Lecture Note 很好地给出了学习理论学习的一个提纲。课程网址请戳这里</span><span style="font-family: 'times new roman', times, serif; font-size: 15.833333015441895px; line-height: 31.66666603088379px; ">（无视频，教授是非常厉害的大牛）</span><span style="font-size: 16px; font-family: 'times new roman', times, serif; line-height: 200%; ">：</span><a href="http://www.cs.berkeley.edu/~bartlett/courses/281b-sp08/" style="font-size: 16px; font-family: 'times new roman', times, serif; line-height: 200%; ">http://www.cs.berkeley.edu/~bartlett/courses/281b-sp08/</a>&nbsp;
	</div>

	<div>
		&nbsp;
	</div>

	<div>
		<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span">好了，最后是对这一篇的结束。</span></span></span>
	</div>

	<div>
		&nbsp;
	</div>

	<div>
		<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span">我窃以为理论分析最迷人之处在于对：（1）这也用证明；（2）这怎么证明；这两类问题的回答。</span></span></span><span style="font-family: 'times new roman', times, serif; font-size: 16px; line-height: 200%; ">第二个问题可能需要艰深的预备知识，敏锐的洞察力，可能非我力所能及。但是一直非常非常喜欢体会一下前辈们怎样解决第一类问题。这一类问题可能构成了某一个topic的根基。</span>
	</div>

	<div>
		&nbsp;
	</div>

	<div>
		<span style="font-family: 'times new roman', times, serif; font-size: 16px; line-height: 200%; ">大部分情况下，理论分析应该是和常识、直观感受、经验等相一致。&ldquo; 这也用证 &rdquo; 类型的问题是我们的常识和经验，但是我们想要推广这种常识，必须有理论研究首先用简洁的符号抽象出问题模型，将外在形式看上去不同但是本质上相同的多个问题全部约减到一个框架下，避免一个一个解决问题这种低效的解决问题方式，然后，在完备的逻辑推理规则上，经过符号演算确定直觉是正确的，确定不存在逻辑推理上的错误。</span>
	</div>

	<div>
		&nbsp;
	</div>

	<div>
		<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span">当然，也有太多异常抽象的结论，很有点 &ldquo; 反直觉 &rdquo; 的意味，只要推理过程在逻辑上是完备的，那么，犯错误的往往都是我们的直觉，错误的直觉会造成思考上的误区。如果某个 &ldquo; 这也用证 &rdquo; 的结论最后被证明在逻辑上是错误的，恐怕会动摇某些topic的根基，毕竟，大多数情况下我们的认知过程是从具体到抽象。很多时候，我们首先按照经验和不同的视角建立起一个一个具体的解决问题的方法，然后再去对这些方法进行分析，最后可能会发现殊途同归，许多方法在本质上是一样的，然后设计出更漂亮的方法。算法分析也是，一些时候通过分析和观察设计的算法工作的挺好，先接受实践的检验，同时也是继续观察，但是真的想要 &ldquo; 用的不虚 &rdquo; ，想要广为流传，就还是一定要从理论上验证算法在最坏情况下的表现。而这些验证往往会从一些看上去 &ldquo; 完全是废话 &rdquo; 的结论开始，但是，实际上也许只是最终结论&nbsp;&ldquo;&nbsp;看上去&rdquo; 废话&nbsp;，分析过程往往并不平凡，这里所谓&ldquo; 废话 &rdquo; 也仅仅是一点比喻。</span></span></span>
	</div>

	<div>
		&nbsp;
	</div>

	<div>
		<span style="font-size: 16px; font-family: 'times new roman', times, serif; line-height: 200%; ">这些结论帮助我们更深刻的理解算法为什么有效，进而设计变种算法，适应不同的情况，算法尽管不能总是有着很好的效果，但是我们会对算法的最差情况有个预估，会明白什么时候有效，什么时候会失效。如果接受不了，至少有机会换一种相对更强的算法。理论分析不一定直接具有可操作性，不一定是在告诉我们怎样训练分类器，但是只有经过理论验证的算法才是敢放心使用可以被驾驭的算法。许多算法在提出之后的很长一段时间内未必会有非常充分的理论分析，但研究最终都会走上这条路。</span>
	</div>

	<div>
		&nbsp;
	</div>

	<div>
		<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span">理论是必要的，经验也很重要。好的结果以理论为基础，然后，经验得来的triks令结果更加犀利。</span></span></span>
	</div>

	<div>
		&nbsp;
	</div>

	<div>
		<span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span">纸上得来终觉浅，绝知此事要躬行。还是继续和老刘一起享受学习的乐趣。</span></span></span>
	</div>

	<div>
		&nbsp;
	</div>

	<div>
		<div style="text-align: center; ">
			<strong><span style="font-family:times new roman,times,serif;"><span style="font-size:16px;"><span data-wiz-span="data-wiz-span">参考文献</span></span></span></strong>
		</div>

		<div>
			<span style="font-size:14px;"><span style="font-family:times new roman,times,serif;"><span data-wiz-span="data-wiz-span">[1].&nbsp;Zhang T. Statistical behavior and consistency of classification methods based on convex risk minimization. Annals of Statistics, 2004: 56-85</span></span></span>
		</div>

		<div>
			<span style="font-size:14px;"><span style="font-family:times new roman,times,serif;"><span data-wiz-span="data-wiz-span">[2]. Rosasco L, De Vito E, Caponnetto A, Piana M, Verri A. Are loss functions all the same. Neural Computation, 2004, 16(5): 1063-1076</span></span></span>
		</div>

		<p>
			<a href="http://www.wiz.cn/i/9aa7f471" style="font-size: 16px; font-family: 'times new roman', times, serif; line-height: 200%; " title="来自为知笔记(Wiz)">来自为知笔记(Wiz)</a>
		</p>

		<p>
			&nbsp;
		</p>
	</div>
</div>


    </body>
</html>

